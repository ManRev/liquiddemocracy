{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## LIST OF PACKAGES NEEDED\n",
    "\n",
    "# %pip install pyirt\n",
    "import irt \n",
    "import csv\n",
    "from pyirt\n",
    "import warnings\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import seaborn as sns\n",
    "import scipy.stats as sp\n",
    "from sklearn import mixture\n",
    "import scipy.stats as stats\n",
    "from kneed import KneeLocator\n",
    "import scipy.special as special\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import ttest_ind\n",
    "from sklearn.cluster import KMeans\n",
    "import scipy.integrate as integrate\n",
    "import matplotlib.gridspec as gridspec\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Settings\n",
    "\n",
    "plt.rc('text', usetex=False) \n",
    "plt.rc('font', family='serif') \n",
    "fontsize_title = 21 \n",
    "fontsize_axis = 17 \n",
    "fontsize_ticks = 13\n",
    "darkblue = \"#2166ac\"\n",
    "lightblue = \"#4393c3\"\n",
    "red = \"#ff6961\"\n",
    "mediumblue = \"cornflowerblue\"\n",
    "palered = \"palevioletred\"\n",
    "green = \"mediumseagreen\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SeabornFig2Grid():\n",
    "    def __init__(self, seaborngrid, fig, subplot_spec):\n",
    "        self.fig = fig\n",
    "        self.sg = seaborngrid\n",
    "        self.subplot = subplot_spec\n",
    "        if isinstance(self.sg, sns.axisgrid.FacetGrid) or \\\n",
    "                    isinstance(self.sg, sns.axisgrid.PairGrid):\n",
    "            self._movegrid()\n",
    "        elif isinstance(self.sg, sns.axisgrid.JointGrid):\n",
    "            self._movejointgrid()\n",
    "        self._finalize()\n",
    "        \n",
    "    def _movegrid(self):\n",
    "        \"\"\" Move PairGrid or Facetgrid \"\"\"\n",
    "        self._resize()\n",
    "        n = self.sg.axes.shape[0]\n",
    "        m = self.sg.axes.shape[1]\n",
    "        self.subgrid = gridspec.GridSpecFromSubplotSpec(n,m, subplot_spec=self.subplot) \n",
    "        for i in range(n):\n",
    "            for j in range(m):\n",
    "                self._moveaxes(self.sg.axes[i,j], self.subgrid[i,j])\n",
    "\n",
    "    def _movejointgrid(self):\n",
    "        \"\"\" Move Jointgrid \"\"\"\n",
    "        h= self.sg.ax_joint.get_position().height\n",
    "        h2= self.sg.ax_marg_x.get_position().height\n",
    "        r = int(np.round(h/h2))\n",
    "        self._resize()\n",
    "        self.subgrid = gridspec.GridSpecFromSubplotSpec(r+1,r+1, subplot_spec=self.subplot) \n",
    "        self._moveaxes(self.sg.ax_joint, self.subgrid[1:, :-1]) \n",
    "        self._moveaxes(self.sg.ax_marg_x, self.subgrid[0, :-1]) \n",
    "        self._moveaxes(self.sg.ax_marg_y, self.subgrid[1:, -1])\n",
    "        \n",
    "    def _moveaxes(self, ax, gs): #https://stackoverflow.com/a/46906599/4124317 ax.remove()\n",
    "        ax.figure=self.fig\n",
    "        self.fig.axes.append(ax) \n",
    "        self.fig.add_axes(ax)\n",
    "        ax._subplotspec = gs \n",
    "        ax.set_position(gs.get_position(self.fig)) \n",
    "        ax.set_subplotspec(gs)\n",
    "\n",
    "    def _finalize(self):\n",
    "        plt.close(self.sg.fig) \n",
    "        self.fig.canvas.mpl_connect(\"resize_event\", self._resize) \n",
    "        self.fig.canvas.draw()\n",
    "\n",
    "    def _resize(self, evt=None): \n",
    "        self.sg.fig.set_size_inches(self.fig.get_size_inches())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_labels = {'TT':'Q1','K':'Q2', 'KK':'Q3', 'T':'Q4', 'PE13':'Q5', 'S':'Q6', 'KKK':'Q7', 'PC':'Q8', 'PCPC':'Q9', 'TTT':'Q10', 'PE8':'Q11', 'PE9':'Q12', 'PPE13':'Q13', 'KKKK':'Q14', 'PE12':'Q15', 'PPPE13':'Q16'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## LIST OF FUNCTIONS NEEDED THROUGHOUT THE ANALYSIS\n",
    "\n",
    "def summary(df): \n",
    "    F_ = []\n",
    "    D_ = []\n",
    "    Q_ = []\n",
    "    C_ = []\n",
    "    F_1 = []\n",
    "    F_2 = []\n",
    "    E_ = []\n",
    "    for name, group in df.groupby('ExpNum'):\n",
    "        for name2, group2 in group.groupby('CodeQuestion'):\n",
    "            fd, dd = np.mean(group2.Answer*group2.Weight), np.mean(group2.Answer)\n",
    "            question, code = list(set(list(group2.CodeQuestion)))[0], list(set(list(group2.CodeExclu)))[0] \n",
    "            expn = name\n",
    "            F_.append(fd)\n",
    "            D_.append(dd)\n",
    "            Q_.append(question)\n",
    "            C_.append(code)\n",
    "            E_.append(expn)\n",
    "            if fd >= dd:\n",
    "                F_1.append(fd)\n",
    "                F_2.append(np.nan) \n",
    "            else:\n",
    "                F_2.append(fd)\n",
    "                F_1.append(np.nan)\n",
    "    data_summary = pd.DataFrame(list(zip(F_, D_, Q_,C_, F_1, F_2, E_)), columns = ['LD', 'DD', 'CodeQuestion', 'CodeExclu', 'LDUP', 'LDDOWN', 'ExpNum'])\n",
    "    return D_, F_, data_summary\n",
    "\n",
    "\n",
    "def ProbaDel(df): \n",
    "    del_proba = []\n",
    "    for i, r in df.iterrows(): \n",
    "        if 'n' in str(r.DelID): \n",
    "            del_proba.append(0)\n",
    "        else: del_proba.append(1)\n",
    "    df['ProbaDel'] = del_proba \n",
    "    return df\n",
    "\n",
    "\n",
    "def plot_occ(df):\n",
    "    perc_del = list(df.groupby(['CodeExclu'], as_index = False).mean().ProbaDel)\n",
    "    dd_v_down = list(df.groupby(['CodeExclu'], as_index = False).std().ProbaDel)\n",
    "    code = list(df.groupby(['CodeExclu'], as_index = False).mean().CodeExclu)\n",
    "    ni = list(df.groupby(['CodeExclu'], as_index = False).count().ID)\n",
    "    code_plot = [dict_labels[k] for k in code]\n",
    "    perc_del, code, dd_v_down, ni, code_plot = zip(*sorted(zip(perc_del, code, dd_v_down, ni, code_plot)))\n",
    "    plt.scatter(code_plot, perc_del, color=darkblue) \n",
    "    plt.xticks(rotation=90, fontsize=18)\n",
    "    plt.yticks(rotation=0, fontsize=18)\n",
    "    plt.title('Frequency of Delegation Per Category', fontsize=21, pad=20) \n",
    "    plt.tick_params(which='minor', bottom=False)\n",
    "    for x in range (len(code)):\n",
    "        top = perc_del[x] + sp.t.ppf(0.975, ni[x]-1)*dd_v_down[x]/np.sqrt(ni[x]-1) \n",
    "        bottom = perc_del[x] - sp.t.ppf(0.975, ni[x]-1)*dd_v_down[x]/np.sqrt(ni[x]-1) \n",
    "        plt.plot([code_plot[x], code_plot[x]], [top, bottom], color=darkblue)\n",
    "\n",
    "\n",
    "def plot_performance_across(data_summary, s):\n",
    "    fig = plt.figure(figsize=(8, 5))\n",
    "    plt.suptitle('Direct Democracy vs. Liquid Democracy', fontsize=fontsize_title) \n",
    "    ax = fig.add_subplot(121)\n",
    "    didi = data_summary.groupby(['CodeExclu']).mean().sort_values('DD') \n",
    "    print(didi)\n",
    "    fd_agg = list(didi.LD)\n",
    "    dd_agg = list(didi.DD)\n",
    "    codes_agg = [k for k in didi.LD.index]\n",
    "    cp=0\n",
    "    ajk=[]\n",
    "    if s == 'e_f':\n",
    "        codes_agg = [str(i) for i in range (len(codes_agg))] \n",
    "    if s == 'q_f':\n",
    "        for k in codes_agg:\n",
    "            if 'P' in k and k!= 'PC':\n",
    "                ajk.append('P' + str(cp))\n",
    "                cp+=1 \n",
    "            else:\n",
    "                ajk.append(k)\n",
    "        codes_agg = ajk\n",
    "    ax.scatter(codes_agg, dd_agg, marker='o', color='cornflowerblue', label='Direct')\n",
    "    ax.scatter(codes_agg, fd_agg, marker='^', color='palevioletred', label='Liquid')\n",
    "\n",
    "    ax.set_ylim(0.5, 1)\n",
    "    ax.set_title('Per Category', fontsize=fontsize_title, pad=20) \n",
    "    ax.tick_params(which='minor', axis='x', labelsize=fontsize_axis, bottom=False) \n",
    "    ax.tick_params(which='minor', axis='y', labelsize=fontsize_axis, bottom=False) \n",
    "    ax.set_xlabel('Category ID', fontsize=fontsize_axis)\n",
    "    ax.set_ylabel('Correct Answer Rate', fontsize=fontsize_axis) \n",
    "    ax.set_ylim(min(min(dd_agg),min(fd_agg))-0.05,max(max(dd_agg),max(fd_agg))+0.05)\n",
    "\n",
    "    ax = fig.add_subplot(122)\n",
    "    data_summary = data_summary.loc[data_summary.CodeExclu != 'SR']\n",
    "    didi = data_summary.groupby(['ExpNum']).mean().sort_values('DD')\n",
    "    fd_agg = list(didi.LD)\n",
    "    dd_agg = list(didi.DD)\n",
    "    codes_agg = [k for k in didi.LD.index]\n",
    "    codes_agg = ['E'+ str(i) for i in range (len(codes_agg))]\n",
    "    ax.scatter(codes_agg, dd_agg, marker='o', color='cornflowerblue', label='Direct') \n",
    "    ax.scatter(codes_agg, fd_agg, marker='^', color='palevioletred', label='Liquid') \n",
    "    ax.set_title('Per Experiment', fontsize=fontsize_title, pad=20) \n",
    "    ax.tick_params(which='minor', axis='x', labelsize=fontsize_axis, bottom=False) \n",
    "    ax.tick_params(which='minor', axis='y', labelsize=fontsize_axis, bottom=False) \n",
    "    ax.set_xlabel('Experiment Number', fontsize=fontsize_axis) \n",
    "    ax.set_ylim(min(min(dd_agg),min(fd_agg))-0.05,max(max(dd_agg),max(fd_agg))+0.05) \n",
    "    plt.legend(loc='lower right')\n",
    "    plt.subplots_adjust(right=0.9)\n",
    "    fig.tight_layout()\n",
    "    plt.savefig('overall_batch2' + s + '.pdf',bbox_inches='tight')\n",
    "\n",
    "\n",
    "def double_std(array): \n",
    "      return np.std(array) * 2\n",
    "\n",
    "\n",
    "def ci(array):\n",
    "    n = len(array)\n",
    "    return sp.t.ppf(0.975, n-1)*sp.sem(array)*np.sqrt(n/(n-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing\n",
    "\n",
    "This section processes the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "focus_on = 'B2'\n",
    "#\"B2\" for main study, \"B1\" for pre-study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## HIGH LEVEL STATISTICS ON AVERAGE PERFORMANCE\n",
    "\n",
    "if focus_on == 'B1':\n",
    "    exp_filter = df.loc[df.ExpNum.isin(['E1','E2','E3','E4','E5','E6'])]\n",
    "else:\n",
    "    exp_filter = df.loc[df.ExpNum.isin(['E8','E9','E10','E11','E12','E13'])]\n",
    "    \n",
    "print(- np.mean(df.Answer) + np.mean(df.Answer*df.Weight))\n",
    "print(- np.mean(exp_filter.Answer) + np.mean(exp_filter.Answer*exp_filter.Weight))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if focus_on == 'B1':\n",
    "    for k in ['E1','E2','E3','E4','E5','E6']:\n",
    "        exp_filter_ = exp_filter.loc[exp_filter.ExpNum==k]\n",
    "        print(np.mean(exp_filter_.Answer), np.mean(exp_filter_.Answer*exp_filter_.Weight))\n",
    "    else:\n",
    "        for k in ['E8','E9','E10','E11','E12','E13']:\n",
    "            exp_filter_ = exp_filter.loc[exp_filter.ExpNum==k]\n",
    "            print(np.mean(exp_filter_.Answer), np.mean(exp_filter_.Answer*exp_filter_.Weight))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## behavior has the average per user per category of metrics such as expertise and information constant across users (such as gender)\n",
    "## behavior_agg is aggregate per use, so that it accounts for probability of delegating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dct= {\n",
    "    'number': 'mean',\n",
    "    'object': lambda col: col.mode() if col.nunique() == 1 else np.nan,\n",
    "}\n",
    "groupby_cols = ['ExpNum', 'ID']\n",
    "dct = {k: v for i in [{col: agg for col in exp_filter.select_dtypes(tp).columns.difference(groupby_cols)} for tp, agg in dct.items()] for k, v in i.items()}\n",
    "behavior_agg = exp_filter.groupby(groupby_cols).agg(**{k: (k, v) for k, v in dct.items()}).reset_index()\n",
    "\n",
    "dct= {\n",
    "    'number': 'mean',\n",
    "    'object': lambda col: col.mode() if col.nunique() == 1 else np.nan,\n",
    "}\n",
    "groupby_cols = ['ExpNum', 'ID', 'CodeExclu']\n",
    "dct = {k: v for i in [{col: agg for col in exp_filter.select_dtypes(tp).columns.difference(groupby_cols)} for tp, agg in dct.items()] for k, v in i.items()}\n",
    "behavior = exp_filter.groupby(groupby_cols).agg(**{k: (k, v) for k, v in dct.items()}).reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistics\n",
    "\n",
    "This section get high-level statistics of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if focus_on == 'B1':\n",
    "    exp_ = ['E1','E2','E3','E4','E5','E6']\n",
    "else:\n",
    "    exp_ = [\"E8\", \"E9\", \"E10\", \"E11\", \"E12\", \"E13\"]\n",
    "tot = 0\n",
    "for k in exp_:\n",
    "    print(\"Number of participants in \", k, \" \", str(len(list(set(df.loc[df.ExpNum == k].ID)))))\n",
    "    tot += len(list(set(df.loc[df.ExpNum == k].ID)))\n",
    "print(\"Number of total participants: \", tot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weight Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = list(exp_filter.groupby('Weight').count().index)\n",
    "c = list(exp_filter.groupby('Weight').count().ID) \n",
    "plt.figure(figsize=(5, 4))\n",
    "plt.xticks(rotation=0, fontsize=fontsize_axis, label='Weight') \n",
    "plt.yticks(rotation=0, fontsize=fontsize_axis, label='Occurences') \n",
    "plt.title('Hitogram of Weights', fontsize=fontsize_title, pad=20) \n",
    "plt.tick_params(which='minor', bottom=False)\n",
    "plt.xlabel('Weights', fontsize=fontsize_axis)\n",
    "plt.ylabel('Occurences', fontsize=fontsize_axis)\n",
    "plt.scatter(w, c, color=darkblue)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if focus_on == 'B1':\n",
    "    dict_size = {\"E1\": 11, \"E2\": 12, \"E3\": 32, \"E4\": 14, \"E5\": 17, \"E6\": 15}\n",
    "else:\n",
    "    dict_size = {\"E8\": 14, \"E9\": 22, \"E10\": 19, \"E11\": 27, \"E12\": 36, \"E13\": 50}\n",
    "size, max_w = [], []\n",
    "avgsize, avgmax_w = [], []\n",
    "for name, group in exp_filter.groupby('ExpNum'):\n",
    "    for k in list(group.groupby('CodeExclu').max().Weight): \n",
    "        size.append(dict_size[name])\n",
    "        max_w.append(k)\n",
    "    avgsize.append(dict_size[name])\n",
    "    avgmax_w.append(np.median(list(group.groupby('CodeExclu').max().Weight)))\n",
    "\n",
    "plt.figure(figsize=(5, 4))\n",
    "plt.xticks(rotation=0, fontsize=fontsize_axis, label='N') \n",
    "plt.yticks(rotation=0, fontsize=fontsize_axis, label='Max Weight') \n",
    "plt.title('Maximum Weight Per Task', fontsize=fontsize_title, pad=20) \n",
    "plt.tick_params(which='minor', bottom=False)\n",
    "plt.xlabel('Experiment Size ($N_e$)', fontsize=fontsize_axis)\n",
    "plt.ylabel('Maximum Weight', fontsize=fontsize_axis)\n",
    "plt.scatter(size, max_w, color=darkblue)\n",
    "plt.scatter(avgsize, avgmax_w, color=red)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "e = []\n",
    "e_label = []\n",
    "for name, group in exp_filter.groupby('ExpNum'):\n",
    "    e.append(dict_size[name])\n",
    "    e_label.append(str(dict_size[name]) + \"\\n (E\" + str(int(name.split('E')[1])-7) + \")\") \n",
    "    max_w = []\n",
    "    for k in list(group.groupby('CodeExclu').max().Weight):\n",
    "            max_w.append(k)\n",
    "            print(k > dict_size[name]/2)\n",
    "    data.append(max_w)\n",
    "\n",
    "medians = [np.median(d) for d in data]\n",
    "\n",
    "e, data, e_label = zip(*sorted(zip(e, data, e_label), key=lambda x: np.median(x[0])))\n",
    "c = mediumblue\n",
    "\n",
    "if focus_on == 'B1':\n",
    "    fig, ax = plt.subplots(figsize=(10, 5)) \n",
    "    ax.boxplot(data, notch=False, patch_artist=True,\n",
    "                    boxprops=dict(facecolor=c, color=c),\n",
    "                    capprops=dict(color=c),\n",
    "                    whiskerprops=dict(color=c),\n",
    "                    flierprops=dict(color=c, markeredgecolor=c), medianprops=dict(color=red), positions=e, widths=0.5)\n",
    "    ax.set_xlabel('Group Size', fontsize=fontsize_axis)\n",
    "    ax.set_ylabel('Maximum Weight', fontsize=fontsize_axis)\n",
    "    ax.set_title('Maximum Weight Box Plot', fontsize=fontsize_title)\n",
    "    ax.set_xticklabels(e_label)\n",
    "    ax.set_xlim([9, 35])\n",
    "    ax.plot([9, 35], [9/2, 35/2], color = green, label = '$N_e/2$')\n",
    "    ax.legend()\n",
    "    plt.savefig('weight_pre.pdf')\n",
    "else:\n",
    "    fig, ax = plt.subplots(figsize=(10, 5)) \n",
    "    ax.boxplot(data, notch=False, patch_artist=True,\n",
    "                    boxprops=dict(facecolor=c, color=c),\n",
    "                    capprops=dict(color=c),\n",
    "                    whiskerprops=dict(color=c),\n",
    "                    flierprops=dict(color=c, markeredgecolor=c), medianprops=dict(color=red), positions=e, widths=3)\n",
    "    ax.set_xlabel('Group Size', fontsize=fontsize_axis)\n",
    "    ax.set_ylabel('Maximum Weight', fontsize=fontsize_axis)\n",
    "    ax.set_title('Maximum Weight Box Plot', fontsize=fontsize_title)\n",
    "    ax.set_xticklabels(e_label)\n",
    "    ax.set_xlim([10, 55])\n",
    "    ax.plot([10, 55], [10/2, 55/2], color = green, label = '$N_e/2$')\n",
    "    ax.legend()\n",
    "    plt.savefig('weight.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delegation Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = mediumblue\n",
    "delegation_per_gender = behavior_agg.groupby(\"gender\").agg([np.mean, double_std, ci])[\"ProbaDel\"] \n",
    "delegation_per_gender = delegation_per_gender.reset_index()\n",
    "delegation_per_gender.gender = delegation_per_gender.gender.str.replace(\"prefer to self-describe\", \"self-describe\") \n",
    "delegation_per_gender.plot(kind = \"scatter\", x = \"gender\", y = \"mean\", legend = False, title = \"\", yerr = \"ci\", color = c, s=50)\n",
    "plt.tick_params(axis='x', labelsize=fontsize_ticks, rotation=0)\n",
    "plt.ylabel('Delegation Frquency', fontsize=fontsize_axis)\n",
    "plt.xlabel('Gender', fontsize=fontsize_axis)\n",
    "plt.tick_params(axis='y', labelsize=fontsize_ticks)\n",
    "plt.title('Delegation Frquency Per Gender', fontsize=fontsize_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "behavior_agg[behavior_agg['gender'].notna()].to_csv('anova.csv')\n",
    "plot_occ(behavior)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimating $q$ and $\\varphi$\n",
    "\n",
    "This section computes the expertise accounting for individual and questions heterogeneity, discusses the bucketing strategies and how to compute $\\varphi$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_filter['unique_id'] = exp_filter['ExpNum'] + '_' + exp_filter['ID'].astype(str)\n",
    "exp_filter['unique_id_q'] = exp_filter['ExpNum'] + '_' + exp_filter['ID'].astype(str) + '_' + exp_filter['CodeExclu']\n",
    "expertise = exp_filter.groupby(['ID', 'ExpNum', 'CodeExclu', \"unique_id\", \"unique_id_q\"]).mean().AverageExpertise.reset_index()\n",
    "\n",
    "questions_score = {}\n",
    "expertise['IRTExpertise'] =  pd.Series([0] * len(expertise))\n",
    "\n",
    "for name, group in exp_filter.groupby([\"CodeExclu\"]):\n",
    "    l = list(group[[\"unique_id_q\", \"CodeQuestion\", \"Answer\"]].itertuples(index=False, name=None))\n",
    "    #item_param, user_param = irt(l)\n",
    "    #item_param, user_param = irt(l, theta_bnds = [0,1], alpha_bnds=[0,1], beta_bnds = [0,1])\n",
    "    #item_param, user_param = irt(l, in_guess_param = {1:{'c':0.0}, 2:{'c':0.5}, 3:{'c':1}})\n",
    "    item_param, user_param = irt(l)\n",
    "    questions_score.update(item_param)\n",
    "    update_b = lambda x: user_param[x['unique_id_q']] if x['unique_id_q'] in user_param else x['IRTExpertise'] \n",
    "    expertise['IRTExpertise'] = expertise.apply(update_b, axis=1)\n",
    "\n",
    "expertise[\"Normalized_IRT\"]  = expertise[\"IRTExpertise\"].subtract(min(expertise[\"IRTExpertise\"])).divide(max(expertise[\"IRTExpertise\"])-min(expertise[\"IRTExpertise\"]))\n",
    "expertise[\"Normalized_IRT_1\"]  = expertise[\"IRTExpertise\"].subtract(min(expertise[\"IRTExpertise\"])).divide((max(expertise[\"IRTExpertise\"])-min(expertise[\"IRTExpertise\"]))/20).subtract(10)\n",
    "\n",
    "np.corrcoef(expertise.AverageExpertise, expertise.Normalized_IRT), np.corrcoef(expertise.AverageExpertise, expertise.Normalized_IRT_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(behavior, expertise, left_on=['ExpNum', 'ID', 'CodeExclu'], right_on=['ExpNum', 'ID', 'CodeExclu'], how='left')\n",
    "merged_df_flat = pd.merge(exp_filter, expertise[['IRTExpertise', 'Normalized_IRT', 'Normalized_IRT_1', 'unique_id_q']], on=[\"unique_id_q\"], how='left')\n",
    "merged_df = merged_df.loc[~(merged_df.CodeExclu == 'S')]\n",
    "\n",
    "if focus_on == 'B2': \n",
    "    merged_df.to_csv('outcome_merged_batch2_lab.csv') \n",
    "    merged_df_flat.to_csv('outcome_merged_flat_batch2_lab.csv')\n",
    "else:\n",
    "    merged_df.to_csv('outcome_merged_batch1_lab.csv') \n",
    "    merged_df_flat.to_csv('outcome_merged_flat_batch1_lab.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2,3, figsize=(15,7))\n",
    "gg_, i_, mini_ = [], [], []\n",
    "e, e_label = [], []\n",
    "data = []\n",
    "dict_all = {}\n",
    "aks = 0\n",
    "for name, group in merged_df.groupby(['ExpNum']):\n",
    "    ax = axes.flatten()[aks]\n",
    "    ma = []\n",
    "    for n, gg in group.groupby('CodeExclu'):\n",
    "        di = {}\n",
    "        g = gg.loc[gg.Weight!=0]\n",
    "        l = sorted(g.Weight, reverse = True) \n",
    "        s=0\n",
    "        i=1\n",
    "        mini = 100\n",
    "        for k in l:\n",
    "            s += k\n",
    "            dict_all[round(i,2)] = round(s/len(gg), 2) \n",
    "            di[i] = round(s/len(gg), 2)\n",
    "            if s/len(gg) > 0.5:\n",
    "                mini = min(mini,i)\n",
    "            i += 1\n",
    "        print(len(gg), i, mini)\n",
    "        gg_.append(len(gg))\n",
    "        i_.append(i)\n",
    "        mini_.append(mini)\n",
    "        ma.append(mini)\n",
    "        ax.scatter(list(di.keys()),list(di.values()))\n",
    "    print(name)\n",
    "    data.append(ma)\n",
    "    e.append(len(gg))\n",
    "    e_label.append(str(len(gg)) + \"\\n (E\" + str(int(name.split('E')[1])-7) + \")\") \n",
    "    ax.set_xlabel(\"Number of Gurus\", fontsize=16)\n",
    "    ax.set_title(\"Experiment \" + str(int(name.split('E')[1])-7) + ' ($N_e=$' + str(len(gg)) + \")\")\n",
    "    aks += 1\n",
    "\n",
    "plt.suptitle('Fraction of Votes (y) Controled by x Gurus', fontsize=fontsize_title)\n",
    "plt.tight_layout()\n",
    "plt.savefig('weights_cdf.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(mini_, i_, color = mediumblue)\n",
    "plt.suptitle('Number of Gurus as a Function \\n of Minimal Number of Gurus \\n that Gathered Half of the Votes', fontsize=fontsize_title)\n",
    "plt.tight_layout()\n",
    "plt.savefig('gurus.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if focus_on == 'B2': \n",
    "    merged_df.groupby('ID').mean()\n",
    "    dct = {\n",
    "        'number': 'mean',\n",
    "        'object': lambda col: col.mode() if col.nunique() == 1 else np.nan,\n",
    "    }\n",
    "    groupby_cols = ['unique_id']\n",
    "    dct = {k: v for i in [{col: agg for col in merged_df.select_dtypes(tp).columns.difference(groupby_cols)} for tp, agg in dct.items()] for k, v in i.items()}\n",
    "    anova = merged_df.groupby(groupby_cols).agg(**{k: (k, v) for k, v in dct.items()}).reset_index() \n",
    "    anova[anova['gender'].notna()].to_csv('anova.csv')\n",
    "    anova.to_csv('anova.csv')\n",
    "\n",
    "behavior.to_csv('behavior.csv')\n",
    "behavior = pd.read_csv('behavior.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(6,3))\n",
    "ax = fig.add_subplot(111)\n",
    "behavior.AverageExpertise.hist(color=mediumblue, label='Naive Expertise: $p^{naive}_i$', bins=15, density = True) \n",
    "expertise.Normalized_IRT.hist(color='red', label='IRT Expertise: $p_i$', bins=15, alpha=0.5, density = True)\n",
    "ax.set_title('Distribution of Expertise', fontsize=fontsize_title, pad=20) \n",
    "ax.tick_params(which='minor', axis='x', labelsize=fontsize_axis, bottom=False) \n",
    "ax.tick_params(which='minor', axis='y', labelsize=fontsize_axis, bottom=False) \n",
    "ax.set_xlabel('Expertise', fontsize=fontsize_axis)\n",
    "ax.set_ylabel('Occurences', fontsize=fontsize_axis) \n",
    "ax.legend()\n",
    "ax.grid(False)\n",
    "fig.tight_layout()\n",
    "plt.subplots_adjust(left=0.1,\n",
    "                    bottom=0.1,\n",
    "                    right=0.9,\n",
    "                    top=0.9,\n",
    "                    wspace=0.2,\n",
    "                    hspace=0.9)\n",
    "if focus_on == 'B1': \n",
    "    plt.savefig('expertise_distribution_pre.pdf',bbox_inches='tight')\n",
    "else: \n",
    "    plt.savefig('expertise_distribution_p.pdf',bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bucketing\n",
    "\n",
    "We then bucket the computed expertise for the $\\varphi$ analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian Mixture \n",
    "\n",
    "(One of the bucketing methods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(list(merged_df.Normalized_IRT)).reshape(-1, 1) \n",
    "\n",
    "# Define a range of n_components values to try\n",
    "n_components_range = range(1, 11) \n",
    "\n",
    "def log_likelihood(estimator, X):\n",
    "    return np.sum(estimator.score_samples(X))\n",
    "\n",
    "# Perform cross-validation\n",
    "cv_scores = []\n",
    "for n_components in n_components_range:\n",
    "    gmm = mixture.GaussianMixture(n_components=n_components,n_init=100,max_iter=50000, covariance_type='full', init_params='random')\n",
    "    scores = cross_val_score(gmm, X, cv=5, scoring=log_likelihood)\n",
    "    cv_scores.append(np.mean(scores))\n",
    "\n",
    "# Find the optimal number of components with the highest cross-validation score\n",
    "optimal_n_components = n_components_range[np.argmax(cv_scores)]\n",
    "\n",
    "# Train the final GMM using the optimal number of components\n",
    "final_gmm = mixture.GaussianMixture(n_components=optimal_n_components)\n",
    "final_gmm.fit(X)\n",
    "\n",
    "# Evaluate the performance of the final GMM\n",
    "final_score = final_gmm.score(X)\n",
    "\n",
    "# Print the optimal number of components and the final score\n",
    "print(\"Optimal number of components:\", optimal_n_components)\n",
    "print(\"Final GMM score:\", final_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain the mean values for each class\n",
    "class_means = final_gmm.means_.flatten()\n",
    "\n",
    "# Sort the mean values and get the corresponding indices\n",
    "sorted_indices = np.argsort(class_means)\n",
    "\n",
    "# Create a mapping dictionary for new labels\n",
    "new_labels = {old_label: new_label for old_label, new_label in enumerate(sorted_indices)}\n",
    "\n",
    "# Update the labels of the GMM model\n",
    "gmm_labels = final_gmm.predict(np.array(list(merged_df.Normalized_IRT)).reshape(-1, 1)) \n",
    "new_gmm_labels = [new_labels[label] for label in gmm_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_means = final_gmm.means_.flatten() \n",
    "dict_m = {}\n",
    "for k in range (len(class_means)):\n",
    "    dict_m[k] = class_means[k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df[\"Labels_GMM\"] = final_gmm.predict(np.array(list(merged_df.Normalized_IRT)).reshape(-1, 1))\n",
    "merged_df[\"Labels_GMM\"] = merged_df[\"Labels_GMM\"].map(dict_m)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8,6))\n",
    "for label, df in merged_df.groupby('Labels_GMM'):\n",
    "    df.Normalized_IRT.plot(kind=\"kde\", ax=ax, label=label)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-means clustering\n",
    "\n",
    "(Another of the bucketing strategies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_closest(x):\n",
    "    return min(l, key=lambda y: abs(y - x)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_kwargs = {\"init\": \"k-means++\",\"n_init\": 10,\"max_iter\": 10000,\"random_state\": 42,}\n",
    "sse = []\n",
    "for k in range(1, 25):\n",
    "    kmeans = KMeans(n_clusters=k, **kmeans_kwargs)\n",
    "    kmeans.fit(X)\n",
    "    sse.append(kmeans.inertia_)\n",
    "kl = KneeLocator(range(1, 25), sse, curve=\"convex\", direction=\"decreasing\")\n",
    "kl.elbow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(init=\"k-means++\", n_clusters=kl.elbow,n_init=10, max_iter=300, random_state=42) \n",
    "kmeans.fit(X)\n",
    "l = kmeans.cluster_centers_\n",
    "l = [k[0] for k in l]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df['Labels_Kmeans'] = merged_df['Normalized_IRT'].apply(find_closest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12,12))\n",
    "\n",
    "ax = fig.add_subplot(321)\n",
    "ax.plot(range(1, 25), sse, color=c)\n",
    "ax.set_title('Sum of Squared Distances \\n of Samples to Closest Cluster Center \\n per Cluster Size', fontsize=fontsize_title, pad=20)\n",
    "ax.tick_params(which='minor', axis='x', labelsize=fontsize_axis, bottom=False)\n",
    "ax.tick_params(which='minor', axis='y', labelsize=fontsize_axis, bottom=False)\n",
    "ax.set_xlabel('Expertise', fontsize=fontsize_axis)\n",
    "ax.set_ylabel('Density', fontsize=fontsize_axis)\n",
    "\n",
    "ax = fig.add_subplot(322)\n",
    "for label, df in merged_df.groupby('Labels_Kmeans'):\n",
    "    df.Normalized_IRT.plot(kind=\"hist\", ax=ax, label=label)\n",
    "ax.set_title('Empirical Distribution \\n of Expertise with \\n 4 K-Mean Clusters', fontsize=fontsize_title, pad=20) \n",
    "ax.tick_params(which='minor', axis='x', labelsize=fontsize_axis, bottom=False)\n",
    "ax.tick_params(which='minor', axis='y', labelsize=fontsize_axis, bottom=False)\n",
    "ax.set_xlabel('Expertise', fontsize=fontsize_axis)\n",
    "ax.set_ylabel('Density', fontsize=fontsize_axis)\n",
    "ax.set_xlim(0, 1)\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.subplots_adjust(left=0.1,\n",
    "                    bottom=0.1,\n",
    "                    right=0.9,\n",
    "                    top=0.9,\n",
    "                    wspace=0.2,\n",
    "                    hspace=0.9)\n",
    "\n",
    "if focus_on == 'B1': \n",
    "    plt.savefig('bucketing1.pdf',bbox_inches='tight')\n",
    "else: \n",
    "    plt.savefig('bucketing2.pdf',bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Phi\n",
    "\n",
    "We use the maximum likelihood estimator here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the number of times where someone with Pi delegates to someone with Pj, stored in Z_MAT as a B*B matrix\n",
    "# (B is the number of buckets)\n",
    "def compute_z(df, expnum, code):\n",
    "    d13 = df.loc[(df.ExpNum == expnum) & (df.CodeExclu == code)]\n",
    "    sdf = d13.loc[d13.ProbaDel == 1]\n",
    "\n",
    "    PI = d13.groupby('Buckets').count().ID.reset_index()\n",
    "    PI_dict = dict(zip(list(PI.Buckets), list(PI.ID)))\n",
    "    PI_dict = {k: v for k, v in PI_dict.items() if v > 0}\n",
    "\n",
    "    s_PI = sdf.groupby('Buckets').count().ID.reset_index()\n",
    "    s_PI_dict = dict(zip(list(s_PI.Buckets), list(s_PI.ID)))\n",
    "    s_PI_dict = {k: v for k, v in s_PI_dict.items() if v > 0}\n",
    "\n",
    "    v_exp_id, v_exp_del = [], []\n",
    "    v_conf_id, v_conf_del = [], []\n",
    "\n",
    "    codeq, idn = [], []\n",
    "    for i, r in d13.iterrows():\n",
    "        if r.Weight == 0:\n",
    "            v_exp_id.append(r.Buckets)\n",
    "            del_exp = \\\n",
    "            list(d13.loc[(d13.ID == r.DelID) & (d13.CodeExclu == r.CodeExclu) & (d13.ExpNum == r.ExpNum)].Buckets)[0]\n",
    "            v_exp_del.append(del_exp)\n",
    "            idn.append(r.ID)\n",
    "        if r.ID == r.GuruID and r.ProbaDel == 1 and len(d13.loc[d13.ID == r.DelID]):\n",
    "            # print(expnum, code, 'cycle')\n",
    "            # print(r)\n",
    "            # print(d13.loc[d13.ID == r.DelID])\n",
    "            v_exp_id.append(r.Buckets)\n",
    "            del_exp = \\\n",
    "            list(d13.loc[(d13.ID == r.DelID) & (d13.CodeExclu == r.CodeExclu) & (d13.ExpNum == r.ExpNum)].Buckets)[0]\n",
    "            v_exp_del.append(del_exp)\n",
    "            idn.append(r.ID)\n",
    "\n",
    "    data_phi13 = pd.DataFrame(list(zip(v_exp_id, v_exp_del, idn)), columns=['I', 'J', 'Count'])\n",
    "\n",
    "    # print(expnum, code, data_phi13)\n",
    "    Z = data_phi13.groupby(['I', 'J']).count().reset_index()\n",
    "    B = sorted(list(set(list(d13.Buckets))))\n",
    "    Z_MAT = []\n",
    "    for pi in B:\n",
    "        Z_j = []\n",
    "        for pj in B:\n",
    "            try:\n",
    "                Z_j.append(list(Z.loc[(Z.I == pi) & (Z.J == pj)].Count)[0])\n",
    "            except:\n",
    "                Z_j.append(0)\n",
    "        Z_MAT.append(Z_j)\n",
    "    return Z_MAT, PI_dict, s_PI_dict\n",
    "\n",
    "\n",
    "# Create the left-hand side of the system of linear equations\n",
    "def computer_M(Z_MAT, map_bucket_to_index, i, PI_dict, B, e, c):\n",
    "    M_I = []\n",
    "    Mi = []\n",
    "    pi_i = PI_dict[i]\n",
    "    z_ii = Z_MAT[map_bucket_to_index[i]][map_bucket_to_index[i]]\n",
    "    pi_i = sum(Z_MAT[map_bucket_to_index[i]])\n",
    "    for l in B:\n",
    "        if l == i:\n",
    "            v = (PI_dict[i] - 1) * (z_ii - pi_i)\n",
    "            Mi.append(v)\n",
    "        else:\n",
    "            v = z_ii * PI_dict[l]\n",
    "            Mi.append(v)\n",
    "    M_I.append(Mi)\n",
    "    for j in B:\n",
    "        if j != i:\n",
    "            Mj = []\n",
    "            # print(e, c, Z_MAT, i, j, map_bucket_to_index, PI_dict)\n",
    "            z_ij = Z_MAT[map_bucket_to_index[i]][map_bucket_to_index[j]]\n",
    "            pi_j = PI_dict[j]\n",
    "            for l in B:\n",
    "                if l == i:\n",
    "                    v = z_ij * (PI_dict[i] - 1)\n",
    "                    Mj.append(v)\n",
    "                if l == j:\n",
    "                    v = (z_ij - pi_i) * pi_j\n",
    "                    Mj.append(v)\n",
    "                if l not in [i, j]:\n",
    "                    v = z_ij * PI_dict[l]\n",
    "                    Mj.append(v)\n",
    "            M_I.append(Mj)\n",
    "    return M_I\n",
    "\n",
    "\n",
    "def get_dataframe(df, i):\n",
    "    df_phi_i = pd.DataFrame(columns=['pj', 'Weight', 'ExpNum', 'CodeExclu'])\n",
    "    for e in list(set(df.ExpNum)):\n",
    "        for c in list(set(df.CodeExclu)):\n",
    "            Z_MAT, PI_dict, s_PI_dict = compute_z(df, e, c)\n",
    "            # print(e, c)\n",
    "            map_ = {}\n",
    "            ki = 0\n",
    "            for k in list(PI_dict.keys()):\n",
    "                map_[k] = ki\n",
    "                ki += 1\n",
    "            # print(map_, PI_dict, list(PI_dict.keys()), i)\n",
    "            # print(e, c, i, i in s_PI_dict.keys())\n",
    "            if i in s_PI_dict.keys() and PI_dict[i] > 1:\n",
    "                # print(PI_dict[i])\n",
    "                M_I = computer_M(Z_MAT, map_, i, PI_dict, list(PI_dict.keys()), e, c)\n",
    "                M_I[0] = [1 for i in range(len(M_I[-1]))]\n",
    "                A = np.array(M_I)\n",
    "                y = np.array([1] + [0] * (len(PI_dict) - 1))\n",
    "                try:\n",
    "                    x = np.linalg.solve(A, y)\n",
    "                    # print(list(PI_dict.keys()), x)\n",
    "                    ee_vec, cc_vec = [e] * len(x), [c] * len(x)\n",
    "                    df_phi2 = pd.DataFrame(list(zip(list(PI_dict.keys()), x, ee_vec, cc_vec)),\n",
    "                                           columns=['pj', 'Weight', 'ExpNum', 'CodeExclu'])\n",
    "                    df_phi_i = df_phi_i.append(df_phi2, ignore_index=True)\n",
    "                    # print(x)\n",
    "                    # print(sum(x))\n",
    "                # print(list(PI_dict.keys()), x)\n",
    "                except:\n",
    "                    print(e, c, i)\n",
    "                    print(A)\n",
    "                    print('Singular Matrix')\n",
    "            if i in s_PI_dict.keys() and PI_dict[i] == 1:\n",
    "                # print(e, c, i, Z_MAT[map_[i]])\n",
    "                ee_vec, cc_vec = [e] * len(Z_MAT[map_[i]]), [c] * len(Z_MAT[map_[i]])\n",
    "                df_phi2 = pd.DataFrame(list(zip(list(PI_dict.keys()), Z_MAT[map_[i]], ee_vec, cc_vec)),\n",
    "                                       columns=['pj', 'Weight', 'ExpNum', 'CodeExclu'])\n",
    "                df_phi_i = df_phi_i.append(df_phi2, ignore_index=True)\n",
    "    return df_phi_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the number of times where someone with Pi delegates to someone with Pj, stored in Z_MAT as a B*B matrix\n",
    "# (B is the number of Labels_GMM)\n",
    "def compute_z_gmm(df, expnum, code):\n",
    "    d13 = df.loc[(df.ExpNum == expnum) & (df.CodeExclu == code)]\n",
    "    sdf = d13.loc[d13.ProbaDel == 1]\n",
    "\n",
    "    PI = d13.groupby('Labels_GMM').count().ID.reset_index()\n",
    "    PI_dict = dict(zip(list(PI.Labels_GMM), list(PI.ID)))\n",
    "    PI_dict = {k: v for k, v in PI_dict.items() if v > 0}\n",
    "\n",
    "    s_PI = sdf.groupby('Labels_GMM').count().ID.reset_index()\n",
    "    s_PI_dict = dict(zip(list(s_PI.Labels_GMM), list(s_PI.ID)))\n",
    "    s_PI_dict = {k: v for k, v in s_PI_dict.items() if v > 0}\n",
    "\n",
    "    v_exp_id, v_exp_del = [], []\n",
    "    v_conf_id, v_conf_del = [], []\n",
    "\n",
    "    codeq, idn = [], []\n",
    "    for i, r in d13.iterrows():\n",
    "        if r.Weight == 0:\n",
    "            v_exp_id.append(r.Labels_GMM)\n",
    "            del_exp = \\\n",
    "            list(d13.loc[(d13.ID == r.DelID) & (d13.CodeExclu == r.CodeExclu) & (d13.ExpNum == r.ExpNum)].Labels_GMM)[0]\n",
    "            v_exp_del.append(del_exp)\n",
    "            idn.append(r.ID)\n",
    "        if r.ID == r.GuruID and r.ProbaDel == 1 and len(d13.loc[d13.ID == r.DelID]):\n",
    "            # print(expnum, code, 'cycle')\n",
    "            # print(r)\n",
    "            # print(d13.loc[d13.ID == r.DelID])\n",
    "            v_exp_id.append(r.Labels_GMM)\n",
    "            del_exp = \\\n",
    "            list(d13.loc[(d13.ID == r.DelID) & (d13.CodeExclu == r.CodeExclu) & (d13.ExpNum == r.ExpNum)].Labels_GMM)[0]\n",
    "            v_exp_del.append(del_exp)\n",
    "            idn.append(r.ID)\n",
    "\n",
    "    data_phi13 = pd.DataFrame(list(zip(v_exp_id, v_exp_del, idn)), columns=['I', 'J', 'Count'])\n",
    "\n",
    "    # print(expnum, code, data_phi13)\n",
    "    Z = data_phi13.groupby(['I', 'J']).count().reset_index()\n",
    "    B = sorted(list(set(list(d13.Labels_GMM))))\n",
    "    Z_MAT = []\n",
    "    for pi in B:\n",
    "        Z_j = []\n",
    "        for pj in B:\n",
    "            try:\n",
    "                Z_j.append(list(Z.loc[(Z.I == pi) & (Z.J == pj)].Count)[0])\n",
    "            except:\n",
    "                Z_j.append(0)\n",
    "        Z_MAT.append(Z_j)\n",
    "    return Z_MAT, PI_dict, s_PI_dict\n",
    "\n",
    "\n",
    "# Create the left-hand side of the system of linear equations\n",
    "def computer_M_gmm(Z_MAT, map_bucket_to_index, i, PI_dict, B, e, c):\n",
    "    M_I = []\n",
    "    Mi = []\n",
    "    pi_i = PI_dict[i]\n",
    "    z_ii = Z_MAT[map_bucket_to_index[i]][map_bucket_to_index[i]]\n",
    "    pi_i = sum(Z_MAT[map_bucket_to_index[i]])\n",
    "    for l in B:\n",
    "        if l == i:\n",
    "            v = (PI_dict[i] - 1) * (z_ii - pi_i)\n",
    "            Mi.append(v)\n",
    "        else:\n",
    "            v = z_ii * PI_dict[l]\n",
    "            Mi.append(v)\n",
    "    M_I.append(Mi)\n",
    "    for j in B:\n",
    "        if j != i:\n",
    "            Mj = []\n",
    "            # print(e, c, Z_MAT, i, j, map_bucket_to_index, PI_dict)\n",
    "            z_ij = Z_MAT[map_bucket_to_index[i]][map_bucket_to_index[j]]\n",
    "            pi_j = PI_dict[j]\n",
    "            for l in B:\n",
    "                if l == i:\n",
    "                    v = z_ij * (PI_dict[i] - 1)\n",
    "                    Mj.append(v)\n",
    "                if l == j:\n",
    "                    v = (z_ij - pi_i) * pi_j\n",
    "                    Mj.append(v)\n",
    "                if l not in [i, j]:\n",
    "                    v = z_ij * PI_dict[l]\n",
    "                    Mj.append(v)\n",
    "            M_I.append(Mj)\n",
    "    return M_I\n",
    "\n",
    "\n",
    "def get_dataframe_gmm(df, i):\n",
    "    df_phi_i = pd.DataFrame(columns=['pj', 'Weight', 'ExpNum', 'CodeExclu'])\n",
    "    for e in list(set(df.ExpNum)):\n",
    "        for c in list(set(df.CodeExclu)):\n",
    "            Z_MAT, PI_dict, s_PI_dict = compute_z_gmm(df, e, c)\n",
    "            # print(e, c)\n",
    "            map_ = {}\n",
    "            ki = 0\n",
    "            for k in list(PI_dict.keys()):\n",
    "                map_[k] = ki\n",
    "                ki += 1\n",
    "            # print(map_, PI_dict, list(PI_dict.keys()), i)\n",
    "            # print(e, c, i, i in s_PI_dict.keys())\n",
    "            if i in s_PI_dict.keys() and PI_dict[i] > 1:\n",
    "                # print(PI_dict[i])\n",
    "                M_I = computer_M_gmm(Z_MAT, map_, i, PI_dict, list(PI_dict.keys()), e, c)\n",
    "                M_I[0] = [1 for i in range(len(M_I[-1]))]\n",
    "                A = np.array(M_I)\n",
    "                y = np.array([1] + [0] * (len(PI_dict) - 1))\n",
    "                try:\n",
    "                    x = np.linalg.solve(A, y)\n",
    "                    # print(list(PI_dict.keys()), x)\n",
    "                    ee_vec, cc_vec = [e] * len(x), [c] * len(x)\n",
    "                    df_phi2 = pd.DataFrame(list(zip(list(PI_dict.keys()), x, ee_vec, cc_vec)),\n",
    "                                           columns=['pj', 'Weight', 'ExpNum', 'CodeExclu'])\n",
    "                    df_phi_i = df_phi_i.append(df_phi2, ignore_index=True)\n",
    "                    # print(x)\n",
    "                    # print(sum(x))\n",
    "                # print(list(PI_dict.keys()), x)\n",
    "                except:\n",
    "                    print(e, c, i)\n",
    "                    print(A)\n",
    "                    print('Singular Matrix')\n",
    "            if i in s_PI_dict.keys() and PI_dict[i] == 1:\n",
    "                # print(e, c, i, Z_MAT[map_[i]])\n",
    "                ee_vec, cc_vec = [e] * len(Z_MAT[map_[i]]), [c] * len(Z_MAT[map_[i]])\n",
    "                df_phi2 = pd.DataFrame(list(zip(list(PI_dict.keys()), Z_MAT[map_[i]], ee_vec, cc_vec)),\n",
    "                                       columns=['pj', 'Weight', 'ExpNum', 'CodeExclu'])\n",
    "                df_phi_i = df_phi_i.append(df_phi2, ignore_index=True)\n",
    "    return df_phi_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We check here that the short closed form matches the unormalized solution above\n",
    "\n",
    "e='E13'\n",
    "c = 'K'\n",
    "Z_MAT, PI_dict, s_PI_dict = compute_z_gmm(merged_df, e, c) \n",
    "map_ = {}\n",
    "ki = 0\n",
    "for k in list(PI_dict.keys()):\n",
    "    map_[k] = ki\n",
    "    ki += 1 \n",
    "phi = []\n",
    "B = sorted(list(set(list(merged_df.Labels_GMM)))) \n",
    "for i in B:\n",
    "    phi_j = [] \n",
    "    for j in B:\n",
    "        z_ij = Z_MAT[map_[i]][map_[j]] \n",
    "        if j == i:\n",
    "            pi_j = PI_dict[j]-1 \n",
    "        else:\n",
    "            pi_j = PI_dict[j]\n",
    "        phi_j.append(z_ij/pi_j)\n",
    "    n_p = []\n",
    "    for k in phi_j:\n",
    "        n_p.append(k/sum(phi_j))\n",
    "    phi.append(n_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buckets_num = 8\n",
    "delta = (max(merged_df.Normalized_IRT) - min(merged_df.Normalized_IRT))/buckets_num\n",
    "cut_offs = [delta*i for i in range(buckets_num + 1)]\n",
    "labels = [round((cut_offs[i]+cut_offs[i+1])/2,2) for i in range (buckets_num)]\n",
    "merged_df['Buckets'] = pd.cut(merged_df.Normalized_IRT, bins = cut_offs, labels=labels, include_lowest=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Equal Cut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = {}\n",
    "for n, g in merged_df.groupby('Buckets'):\n",
    "             labels[n] = np.mean(g.Normalized_IRT)\n",
    "\n",
    "merged_df['Buckets'] = merged_df['Buckets'].map(labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quantile Cut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df['Buckets'] = pd.qcut(merged_df.Normalized_IRT, buckets_num) \n",
    "labels = []\n",
    "for n, g in merged_df.groupby('Buckets'):\n",
    "    labels.append(np.median(g.Normalized_IRT))\n",
    "\n",
    "merged_df['Buckets'] = pd.qcut(merged_df.Normalized_IRT, buckets_num, labels =labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "method = 'Buckets' #'Buckets', \"GMM\"\n",
    "merged_df[\"Labels_GMM\"] = merged_df[\"Labels_Kmeans\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if method == 'Buckets':\n",
    "    B = sorted(list(set(list(merged_df.Buckets))))\n",
    "    df_phi_tot = pd.DataFrame(columns=['pj', 'Weight'])\n",
    "    kf = 0\n",
    "    d_weights_total = pd.DataFrame(columns=['pj', 'Weight', 'ExpNum', 'CodeExclu', 'pi']) \n",
    "    for i in B:\n",
    "        df_phi_i = get_dataframe(merged_df[['ID', 'DelID', 'CodeExclu', 'ExpNum', 'Buckets', 'Weight', 'ProbaDel', 'GuruID']], i)\n",
    "        df_phi_i[\"pi\"] = [i]*len(df_phi_i)\n",
    "\n",
    "        # Store the per exp per task (pi, pj) pair\n",
    "        d_weights_total = d_weights_total.append(df_phi_i, ignore_index=True)\n",
    "        \n",
    "        # Take the average weight per pair\n",
    "        new_d = df_phi_i.groupby('pj').mean().reset_index()\n",
    "        dd_i = pd.DataFrame(list(zip(list(df_phi_i.pj), list(df_phi_i.Weight))), columns=['pj', 'Weight']) \n",
    "        df_phi_tot = df_phi_tot.append(dd_i, ignore_index=True)\n",
    "\n",
    "if method == 'gmm':\n",
    "    B = sorted(list(set(list(merged_df.Labels_GMM))))\n",
    "    df_phi_tot = pd.DataFrame(columns=['pj', 'Weight'])\n",
    "    kf = 0\n",
    "    d_weights_total = pd.DataFrame(columns=['pj', 'Weight', 'ExpNum', 'CodeExclu', 'pi']) \n",
    "    for i in B:\n",
    "        df_phi_i = get_dataframe_gmm(merged_df[['ID', 'DelID', 'CodeExclu', 'ExpNum', 'Labels_GMM', 'Weight', 'ProbaDel', 'GuruID']], i)\n",
    "        df_phi_i[\"pi\"] = [i]*len(df_phi_i)\n",
    "\n",
    "        # Store the per exp per task (pi, pj) pair\n",
    "        d_weights_total = d_weights_total.append(df_phi_i, ignore_index=True)\n",
    "\n",
    "        # Take the average weight per pair\n",
    "        new_d = df_phi_i.groupby('pj').mean().reset_index()\n",
    "        dd_i = pd.DataFrame(list(zip(list(df_phi_i.pj), list(df_phi_i.Weight))), columns=['pj', 'Weight']) \n",
    "        df_phi_tot = df_phi_tot.append(dd_i, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = stats.kendalltau(d_weights_total.Weight, d_weights_total.pj)\n",
    "print(res)\n",
    "for name, group in d_weights_total.groupby('pi'): \n",
    "    print(stats.kendalltau(group.Weight, group.pj))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tot=0\n",
    "for i in B:\n",
    "    filter_ = d_weights_total.loc[d_weights_total.pi == i]\n",
    "    new_d = filter_.groupby('pj').agg({'Weight': 'mean'}).reset_index()\n",
    "    print(sum(new_d.Weight))\n",
    "    new_d.Weight = new_d.Weight.divide(sum(new_d.Weight))\n",
    "    x = np.array(list(new_d.pj)).reshape((-1, 1))\n",
    "    y = np.array(list(new_d.Weight))\n",
    "    model = LinearRegression().fit(x, y)\n",
    "    r_sq = model.score(x, y)\n",
    "\n",
    "    print('coefficient of determination:', r_sq)\n",
    "    print('intercept:', model.intercept_)\n",
    "    print('slope:', model.coef_)\n",
    "\n",
    "    tot += model.coef_[0]\n",
    "    x = np.array(list(filter_.pj)).reshape((-1, 1))\n",
    "    y = np.array(list(filter_.Weight))\n",
    "    model = LinearRegression().fit(x, y)\n",
    "    r_sq = model.score(x, y)\n",
    "\n",
    "    print('coefficient of determination:', r_sq)\n",
    "    print('intercept:', model.intercept_)\n",
    "    print('slope:', model.coef_)\n",
    "    print()\n",
    "tot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(3,3, figsize=(7,7))\n",
    "\n",
    "for i, prog in enumerate(B[:buckets_num+1]):\n",
    "    filter_ = d_weights_total.loc[d_weights_total.pi == prog]\n",
    "    new_d = filter_.groupby('pj').agg({'Weight': 'mean'}).reset_index()\n",
    "    ax = axes.flatten()[i]\n",
    "    ax.grid(False)\n",
    "    sns.scatterplot(x='pj', y='Weight', data=filter_, color=mediumblue, ax=ax, marker='+') \n",
    "    sns.regplot(x='pj', y='Weight', data=new_d, scatter=True, color=red, ax=ax) \n",
    "    ax.set_xlabel('$\\eta_k$', fontsize=16) \n",
    "    ax.set_ylabel('$\\phi^{'+str(round(prog,2))+'}$($\\eta_k$)', fontsize=16) \n",
    "    print(sum(new_d.Weight))\n",
    "\n",
    "fig.delaxes(axes[2][1])\n",
    "fig.delaxes(axes[2][2])\n",
    "plt.suptitle('$\\phi$ function for various expertise levels', fontsize=fontsize_title)\n",
    "plt.tight_layout()\n",
    "\n",
    "if focus_on == 'B1': \n",
    "    plt.savefig('phi_batch1_gmm.pdf')\n",
    "else: \n",
    "    plt.savefig('phi_7_q.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_d = d_weights_total.groupby('pj').agg({'Weight': 'mean'}).reset_index() \n",
    "new_d.Weight = new_d.Weight.divide(sum(new_d.Weight))\n",
    "sns.scatterplot(x='pj', y='Weight', data=d_weights_total, color=mediumblue, marker='+') \n",
    "sns.regplot(x='pj', y='Weight', data=new_d, scatter=True, color=red) \n",
    "plt.suptitle('Estimation of $\\phi$ Across all Levels', fontsize=fontsize_title) \n",
    "plt.xlabel(\"$\\eta_{k}$\", fontsize = fontsize_axis)\n",
    "plt.ylabel(\"$\\phi(\\eta_{k})$\", fontsize = fontsize_axis) \n",
    "plt.tight_layout()\n",
    "print(sum(new_d.Weight))\n",
    "\n",
    "if focus_on == 'B1': \n",
    "    plt.savefig('phi_agg_pre_gmm.pdf')\n",
    "else: \n",
    "    plt.savefig('phi_agg_7_q.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array(list(new_d.pj)).reshape((-1, 1))\n",
    "y = np.array(list(new_d.Weight))\n",
    "model = LinearRegression().fit(x, y)\n",
    "r_sq = model.score(x, y)\n",
    "print('coefficient of determination:', r_sq)\n",
    "print('intercept:', model.intercept_)\n",
    "print('slope:', model.coef_)\n",
    "        \n",
    "x = np.array(list(d_weights_total.pj)).reshape((-1, 1))\n",
    "y = np.array(list(d_weights_total.Weight))\n",
    "model = LinearRegression().fit(x, y)\n",
    "r_sq = model.score(x, y)\n",
    "print('coefficient of determination:', r_sq)\n",
    "print('intercept:', model.intercept_)\n",
    "print('slope:', model.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if focus_on == 'B1': \n",
    "    d_weights_total.to_csv('phi_w_batch1_k.csv')\n",
    "else: \n",
    "    d_weights_total.to_csv('phi_w_gmm.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_weights_total = pd.read_csv('phi_w_gmm.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = stats.kendalltau(d_weights_total.Weight, d_weights_total.pj)\n",
    "print(res)\n",
    "for name, group in d_weights_total.groupby('pi'):\n",
    "    print(stats.kendalltau(group.Weight, group.pj))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(data=merged_df, x=\"Labels_GMM\", y=\"ProbaDel\", err_style=\"band\", errorbar=(\"se\", 2),)\n",
    "plt.suptitle('Estimation of $q$ Across all Levels', fontsize=fontsize_title) \n",
    "plt.xlabel(\"$\\eta_{k}$\", fontsize = fontsize_axis) \n",
    "plt.ylabel(\"$q(\\eta_{k})$\", fontsize = fontsize_axis)\n",
    "plt.tight_layout()\n",
    "plt.savefig('q_agg_b1.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Liquid v. Direct\n",
    "\n",
    "This section compares the performance of liquid and direct democracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df_flat['LDest'] = merged_df_flat.Answer*merged_df_flat.Weight\n",
    "newdd = merged_df_flat[[\n",
    "         'ID',\n",
    "         'DelID',\n",
    "         'GuruID',\n",
    "         'Answer',\n",
    "         'AverageExpertise',\n",
    "         'Weight',\n",
    "         'Confidence',\n",
    "         'AvergeConfidence',\n",
    "         'CodeQuestion',\n",
    "         'CodeExclu',\n",
    "         'ExpNum',\n",
    "         'gender',\n",
    "         'unique_id', 'IRTExpertise', 'Normalized_IRT','Normalized_IRT_1']] \n",
    "\n",
    "newdd['Cat'] = [0 for k in range (len(newdd))]\n",
    "newld = merged_df_flat[[\n",
    "         'ID',\n",
    "         'DelID',\n",
    "         'GuruID',\n",
    "         'LDest',\n",
    "         'AverageExpertise',\n",
    "         'Weight',\n",
    "         'Confidence',\n",
    "         'AvergeConfidence',\n",
    "         'CodeQuestion',\n",
    "         'CodeExclu',\n",
    "         'ExpNum',\n",
    "         'gender',\n",
    "         'unique_id', 'IRTExpertise', 'Normalized_IRT','Normalized_IRT_1']] \n",
    "newld['Cat'] = [1 for k in range (len(newld))]\n",
    "newdd = newdd.rename(columns={'Answer':'Estimate'}) \n",
    "newld = newld.rename(columns={'LDest':'Estimate'}) \n",
    "df_flat = pd.concat([newdd, newld], sort=False) \n",
    "np.mean(newld.Estimate), np.mean(newdd.Estimate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "codes_agg1 = []\n",
    "codes_agg2 = []\n",
    "codes_agg3 = []\n",
    "dd_agg, fd_agg = [], []\n",
    "s_dd_agg, s_fd_agg = [], []\n",
    "for name, group in exp_filter.groupby('ExpNum'):\n",
    "    for name1, group1 in group.groupby('CodeQuestion'):\n",
    "        dd = np.mean(group1.Answer)\n",
    "        fd = np.mean(group1.Answer*group1.Weight)\n",
    "        sdd = np.var(group1.Answer)\n",
    "        sfd = np.var(group1.Answer*group1.Weight)\n",
    "        c1, c2, c3 = name, name1, list(group1.CodeExclu)[0]\n",
    "        dd_agg.append(dd)\n",
    "        fd_agg.append(fd)\n",
    "        s_dd_agg.append(dd)\n",
    "        s_fd_agg.append(fd)\n",
    "        codes_agg1.append(c1)\n",
    "        codes_agg2.append(c2)\n",
    "        codes_agg3.append(c3)\n",
    "\n",
    "newdd = pd.DataFrame(list(zip(codes_agg1, codes_agg2, codes_agg3, dd_agg)), columns=['ExpNum', 'CodeQuestion', 'CodeExclu', 'DD'])\n",
    "newfd = pd.DataFrame(list(zip(codes_agg1, codes_agg2, codes_agg3, fd_agg)), columns=['ExpNum', 'CodeQuestion', 'CodeEx clu', 'LD'])\n",
    "newdd['Cat'] = [0 for k in range (len(newdd))]\n",
    "newfd['Cat'] = [1 for k in range (len(newfd))]\n",
    "newdd = newdd.rename(columns={'DD':'Estimate'}) \n",
    "newfd = newfd.rename(columns={'LD':'Estimate'}) \n",
    "\n",
    "if focus_on == 'B1':\n",
    "    pd.concat([newdd, newfd], sort=False).to_csv('LDvDD_batch1.csv') \n",
    "else:\n",
    "    pd.concat([newdd, newfd], sort=False).to_csv('LDvDD.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "codes_agg1 = []\n",
    "codes_agg2 = []\n",
    "codes_agg3 = []\n",
    "dd_agg, fd_agg = [], []\n",
    "s_dd_agg, s_fd_agg = [], []\n",
    "for name, group in merged_df.groupby('ExpNum'):\n",
    "    for name1, group1 in merged_df.groupby('CodeExclu'):\n",
    "        dd = np.mean(group1.Normalized_IRT)\n",
    "        fd = np.mean(group1.Normalized_IRT*group1.Weight)\n",
    "        sdd = np.var(group1.Normalized_IRT)\n",
    "        sfd = np.var(group1.Normalized_IRT*group1.Weight)\n",
    "        c1, c2 = name, name1\n",
    "        dd_agg.append(dd)\n",
    "        fd_agg.append(fd)\n",
    "        s_dd_agg.append(dd)\n",
    "        s_fd_agg.append(fd)\n",
    "        codes_agg1.append(c1)\n",
    "        codes_agg2.append(c2)\n",
    "\n",
    "newdd = pd.DataFrame(list(zip(codes_agg1, codes_agg2, dd_agg)), columns=['ExpNum', 'CodeExclu', 'DD'])\n",
    "newfd = pd.DataFrame(list(zip(codes_agg1, codes_agg2, fd_agg)), columns=['ExpNum', 'CodeExclu', 'LD']) \n",
    "newdd['Cat'] = [0 for k in range (len(newdd))]\n",
    "newfd['Cat'] = [1 for k in range (len(newfd))]\n",
    "newdd = newdd.rename(columns={'DD':'Estimate'})\n",
    "newfd = newfd.rename(columns={'LD':'Estimate'}) \n",
    "\n",
    "if focus_on == 'B1':\n",
    "    pd.concat([newdd, newfd], sort=False).to_csv('LDvDD_means_batch1.csv') \n",
    "else:\n",
    "    pd.concat([newdd, newfd], sort=False).to_csv('LDvDD_means.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the average for 'Direct' and 'Liquid' by 'CodeExclu'\n",
    "both, none, direct, liquid = 0, 0, 0, 0\n",
    "exp, code, codee, est, outcome_d, outcome_l = [], [], [], [], [], []\n",
    "for i, r in merged_df_flat.groupby(['ExpNum', 'CodeQuestion']):\n",
    "    qboth, qnone, qdirect, qliquid = 0, 0, 0, 0\n",
    "    exp.append(i[0])\n",
    "    code.append(i[1])\n",
    "    codee.append(list(r.CodeExclu)[0])\n",
    "    if sum([np.mean(r.Answer)>0.5, np.mean(r.Answer*r.Weight)>0.5]) == 2:\n",
    "        both += 1\n",
    "        qboth += 1\n",
    "        outcome_d.append(1)\n",
    "        outcome_l.append(1)\n",
    "        est.append(1)\n",
    "        est.append(0)\n",
    "    if sum([np.mean(r.Answer)>0.5, np.mean(r.Answer*r.Weight)>0.5]) == 0:\n",
    "        none += 1\n",
    "        qnone += 1\n",
    "        outcome_d.append(0)\n",
    "        outcome_l.append(0)\n",
    "        est.append(1)\n",
    "        est.append(0)\n",
    "    if sum([np.mean(r.Answer)>0.5, np.mean(r.Answer*r.Weight)>0.5]) == 1:\n",
    "        if np.mean(r.Answer)>0.5:\n",
    "            direct += 1\n",
    "            print(i)\n",
    "            outcome_l.append(0)\n",
    "            outcome_d.append(1)\n",
    "            est.append(1)\n",
    "            est.append(0)\n",
    "        else:\n",
    "            liquid +=1 \n",
    "            print('w')\n",
    "            print(i)\n",
    "            outcome_l.append(1)\n",
    "            outcome_d.append(0)\n",
    "            est.append(1)\n",
    "            est.append(0)\n",
    "\n",
    "correct = pd.DataFrame({'ExpNum':exp, 'CodeQuestion':code, 'CodeExclu': codee, 'Direct':outcome_d, 'Liquid':outcome_l})\n",
    "grouped_data = correct.groupby('CodeExclu').mean().sort_values('Direct') \n",
    "\n",
    "# Reset index for plotting\n",
    "grouped_data = grouped_data.reset_index() \n",
    "\n",
    "# Set up the plot\n",
    "plt.figure(figsize=(4,5))\n",
    "plt.scatter(x=grouped_data['CodeExclu'].map(dict_labels), y=grouped_data['Direct'], marker='o', label='Direct', color = mediumblue)\n",
    "plt.scatter(x=grouped_data['CodeExclu'].map(dict_labels), y=grouped_data['Liquid'], marker='^', label='Liquid', color = red)\n",
    "\n",
    "plt.xlabel('Task', fontsize=fontsize_axis)\n",
    "plt.ylabel('Correct Outcome Rate', fontsize=fontsize_axis)\n",
    "plt.title('Frequency at Which \\n Liquid and Direct \\n Democracies Are Correct', fontsize=fontsize_title, pad=20) \n",
    "plt.legend()\n",
    "plt.grid(False)\n",
    "plt.xticks(rotation=90, fontsize=15)\n",
    "plt.yticks(rotation=0, fontsize=15)\n",
    "plt.tick_params(which='minor', bottom=False)\n",
    "plt.legend(fontsize=15, loc='upper left')\n",
    "plt.tight_layout()\n",
    "\n",
    "if focus_on == 'B1': \n",
    "    plt.savefig('correct_batch1.pdf',bbox_inches='tight')\n",
    "else: \n",
    "    plt.savefig('correct.pdf',bbox_inches='tight')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
